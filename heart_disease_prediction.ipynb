{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd48dad5",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction Model\n",
    "The dataset is from Kaggle, linked here: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset. However, the majority of its rows duplicate entries to greatly inflate its size, which are dropped before loading in the CSV file to match the original size of the source on UCI's Cleveland Heart Disease dataset.\n",
    "\n",
    "This notebook builds a binary classification model to predict the presence of heart disease using clinical data. The goal is to identify high-risk individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aeb9da",
   "metadata": {},
   "source": [
    "## Domain Background\n",
    "\n",
    "Heart disease (coronary artery disease) is a condition caused by narrowed arteries reducing blood flow to the heart. Key clinical features include chest pain types, blood pressure, cholesterol levels, and exercise-induced symptoms. These features help predict the presence of heart disease using standard diagnostic tests like ECG and stress tests.\n",
    "\n",
    "*This project is for educational purposes only and does not provide medical advice.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802bee5",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "- pandas, numpy: for data loading, manipulation, and numerical operations\n",
    "\n",
    "- matplotlib.pyplot, seaborn: for plotting histograms, heatmaps, ROC curves, and other visualizations\n",
    "\n",
    "- sklearn.model_selection: for train/test splitting and k-fold cross-validation\n",
    "\n",
    "- sklearn.pipeline, sklearn.compose.ColumnTransformer: for building end-to-end preprocessing and modeling pipelines\n",
    "\n",
    "- sklearn.preprocessing: for scaling numeric features and one-hot encoding categoricals\n",
    "\n",
    "- sklearn.impute: to handle missing values \n",
    "\n",
    "- sklearn.linear_model.LogisticRegression: the classifier used to predict heart disease presence\n",
    "\n",
    "- sklearn.metrics: to evaluate model performance (ROC-AUC, F1 Score, confusion matrix, etc.)\n",
    "\n",
    "- joblib: to save and load the trained model for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report, confusion_matrix, RocCurveDisplay\n",
    "import joblib\n",
    "\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6980358",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "We start by performing basic checks on the loaded DataFrame through Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986dc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_basic_info(df, show=True):\n",
    "    \"\"\"No return value, prints basic information & missing values in the given DataFrame.\"\"\"\n",
    "    if not show:\n",
    "        return\n",
    "    print(df.head())\n",
    "    print(\"\\nInfo: \")\n",
    "    print(df.info())\n",
    "    print(\"\\nDescription: \")\n",
    "    print(df.describe())\n",
    "    print('\\nMissing values: ')\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a30be",
   "metadata": {},
   "source": [
    "The dataset contains 1025 records spanning the following features:\n",
    "\n",
    "- **age**: Numeric (years)  \n",
    "\n",
    "- **sex**: Binary (0 = female, 1 = male) \n",
    "\n",
    "- **cp (chest pain type)**: Categorical  \n",
    "  - 0 = typical angina  \n",
    "  - 1 = atypical angina  \n",
    "  - 2 = non-anginal pain  \n",
    "  - 3 = asymptomatic  \n",
    "\n",
    "- **trestbps (resting blood pressure)**: Numeric (mm Hg)  \n",
    "\n",
    "- **chol (serum cholesterol)**: Numeric (mg/dl)  \n",
    "\n",
    "- **fbs (fasting blood sugar > 120 mg/dl)**: Binary (1 = true, 0 = false) \n",
    "\n",
    "- **restecg (resting ECG results)**: Categorical  \n",
    "  - 0 = normal  \n",
    "  - 1 = ST-T wave abnormality  \n",
    "  - 2 = probable or definite left ventricular hypertrophy  \n",
    "\n",
    "- **thalach (maximum heart rate achieved)**: Numeric  \n",
    "\n",
    "- **exang (exercise-induced angina)**: Binary (1 = yes, 0 = no)  \n",
    "\n",
    "- **oldpeak**: Numeric (ST depression induced by exercise relative to rest; float)  \n",
    "\n",
    "- **slope (of peak exercise ST segment)**: Categorical  \n",
    "  - 0 = upsloping  \n",
    "  - 1 = flat  \n",
    "  - 2 = downsloping  \n",
    "\n",
    "- **ca (number of major vessels visualized by fluoroscopy)**: Numeric (0–4)  \n",
    "\n",
    "- **thal**: Categorical  \n",
    "  - 1 = normal  \n",
    "  - 2 = fixed defect  \n",
    "  - 3 = reversible defect  \n",
    "\n",
    "- **target**: Binary target variable (0 = no heart disease, 1 = presence of heart disease)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Pandas does not pick up on any NaN values, but we can see that \"thal\" contains a small amount of values of 0, though it is encoded to only contain values 1-3. 0 likely indicates missing records.\n",
    "\n",
    "The columns \"ca\" and \"thal\" both involve the results of imaging tests, which are typically performed on patients who have identified risk. The inclusion of these features could imply that the individuals in the dataset have already been identified as high-risk for heart disease at the time of data collection. Therefore, this model predicts heart disease using all available data, and may not be suitable for early risk prediction when less clinical information is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83696df",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97113971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_distribution(df, col, plot=True, save=False):\n",
    "    \"\"\"Plots a Histogram/KDE of a given col, designed for numericals.\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.xlabel(col)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_num_distribution_{col}.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_cat_distribution(df, col, plot=True, save=False):\n",
    "    \"\"\"Plots countplots of a given col, designed for categoricals.\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_cat_distribution_{col}.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_cat_to_target(df, col, target='target', plot=True, save=False):\n",
    "    \"\"\"Plots mean of target variable by category in col.\"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(data=df, x=col, y=target)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"Proportion of {target}=1 by {col}\")\n",
    "    plt.ylabel(f\"Mean {target}\")\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_target_{col}.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "def plot_num_to_target(df, col, target='target', plot=True, save=False):\n",
    "    \"\"\"Plots boxplots & violinplots of (numeric) col vs target.\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.violinplot(data=df, x=target, y=col, inner=None, color='steelblue')\n",
    "    sns.boxplot(data=df, x=target, y=col, width=0.1, boxprops={'facecolor':'none'})\n",
    "    plt.xlabel(target)\n",
    "    plt.ylabel(col)\n",
    "    plt.title(f\"{target} by {col}\")\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_target_{col}.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "def plot_binary_to_target(df, col, target='target', plot=True, save=False):\n",
    "    \"\"\"Plots countplots for binary cols vs target.\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.countplot(data=df, x=col, hue=target)\n",
    "    plt.title(f\"Countplot of {col} grouped by {target}\")\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_target_{col}.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_corr_heatmap(df, num_cols, target='target', plot=True, save=False):\n",
    "    \"Plots a heatmap showing correlation between numerical cols.\"\n",
    "    plt.figure(figsize=(12,10))\n",
    "    corr = df[num_cols + [target]].corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    if save:\n",
    "        plt.savefig(f\"heatmap.png\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def eda_utility(df, cat_cols, num_cols, bin_cols, target='target', plot=True, save=True):\n",
    "    \"\"\"Loops through all EDA functions above. Plots and/or saves according to parameters.\"\"\"\n",
    "    if not plot and not save:\n",
    "        return\n",
    "    \n",
    "    plot_corr_heatmap(df, num_cols, target, plot=plot, save=save)\n",
    "    plot_cat_distribution(df, target, plot=plot, save=save)\n",
    "\n",
    "    for col in num_cols:\n",
    "        plot_num_distribution(df, col, plot=plot, save=save)\n",
    "        plot_num_to_target(df, col, plot=plot, save=save)\n",
    "    \n",
    "    for col in cat_cols + bin_cols:\n",
    "        plot_cat_distribution(df, col, plot=plot, save=save)\n",
    "        plot_cat_to_target(df, col, plot=plot, save=save)\n",
    "\n",
    "    for col in bin_cols:\n",
    "        plot_binary_to_target(df, col, plot=plot, save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc7b985",
   "metadata": {},
   "source": [
    "### EDA Takeaways\n",
    "- The heatmap correlation analysis shows that maximum heart rate achieved (`thalach`), ST depression during exercise (`oldpeak`), and number of major vessels affected (`ca`) have the strongest relationships with heart disease status. Specifically, lower max heart rate, higher ST depression, and more affected vessels are associated with increased risk. Age also shows moderate correlation, influencing heart function indicators like max heart rate and ST depression.\n",
    "\n",
    "- `restecg` has only 15 records labeled '2' (left ventricular hypertrophy), compared to 1,010 records labeled '0' (normal) or '1' (ST-T abnormality). Although the target mean for '2' is lower, the very small sample size makes this statistic unreliable. Because of the limited data, the model might not generalize well for this subgroup. To account for that, the feature will later be collapsed into a binary variable: '0' = normal and '1' = any abnormality (combining '1' and '2'). This reduces the chance of overfitting to a small class. More data would be needed to accurately model risk among individuals with left ventricular hyptertrophy.\n",
    "\n",
    "- `thal` has a small amount of missing values, coded as 0. Because the amount is small, imputing with the most common category is a reasonable approach to maintain data integrity without losing other data in the samples.\n",
    "\n",
    "- There is a class imbalance in `sex`, showing that the dataset is mostly men. The model may generalize better for men.\n",
    "\n",
    "- `age` shows that the dataset focuses on middle-aged to senior adults, so the model may not generalize to younger individuals.\n",
    "\n",
    "- The target variable is balanced, so no imbalance handling is needed for it.\n",
    "\n",
    "- `chol` (cholesterol) and `trestbps` (resting blood pressure) are somewhat right-skewed and have wide ranges of values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9217840",
   "metadata": {},
   "source": [
    "## Creating Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_pipeline(df):\n",
    "    \"\"\"Cleaning steps before running data through model preprocessor pipeline.\"\"\"\n",
    "    df = df.copy()\n",
    "    # Collapse restecg into binary\n",
    "    df['restecg'] = df['restecg'].replace({2:1})\n",
    "    # Replace thal 0 values with NaN\n",
    "    df['thal'] = df['thal'].replace(0, np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def build_preprocessor(num_cols, cat_cols):\n",
    "    \"\"\"\n",
    "    Builds the preprocessing pipelines for numeric and categorical features.\n",
    "    Numerical cols: scales.\n",
    "    Categorical cols: Imputes missing values (only in thal), uses one hot encoding.\n",
    "    Returns preprocessing transformer.\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "def build_model(preprocessor):\n",
    "    \"\"\"Returns the pipeline of preprocessing & the XGBoost Classification model.\"\"\"\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(solver='liblinear', penalty='l2', C=1.0, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, X, y, test_size=0.2):\n",
    "    \"\"\"Splits data into train and test sets, fits model, and returns the trained pipeline along with test sets.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, X_test, y_test\n",
    "\n",
    "\n",
    "def evaluate_model_cv(model, X, y, cv=5):\n",
    "    \"\"\"K-fold cross-validation using roc_auc_score.\"\"\"\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
    "    print('\\n')\n",
    "    print(f\"CV ROC-AUC scores: {scores}\")\n",
    "    print(f\"Mean CV ROC-AUC: {scores.mean():.4f}\")\n",
    "    print(f\"STD CV ROC-AUC: {scores.std():.4f}\")\n",
    "    print('\\n')\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluates the trained model on the holdout set.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"\\nHoldout Test Set Eval:\")\n",
    "    print(f\"\\nROC-AUC: {auc:.4f}\")\n",
    "    print(f\"\\nF1 Score: {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_estimator(model, X_test, y_test, name='LogisticRegression')\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_feature_importance(model, num_cols, cat_cols):\n",
    "    \"\"\"Plots the feature importance of trained model using logistic regression coefficients.\"\"\"\n",
    "\n",
    "    preprocessor = model.named_steps['preprocessor']\n",
    "    classifier = model.named_steps['classifier']\n",
    "\n",
    "    # create feature list: numerical plus decoded categorical names\n",
    "    features = num_cols + list(preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols))\n",
    "\n",
    "    coefs = classifier.coef_[0]\n",
    "\n",
    "    # creates df of features and corresponding coefficient\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'coefficient': coefs\n",
    "    })\n",
    "\n",
    "    # sorts coefficients by absolute value in new col\n",
    "    coef_df['abs_coef'] = coef_df['coefficient'].abs()\n",
    "    coef_df = coef_df.sort_values('abs_coef', ascending=False)\n",
    "\n",
    "\n",
    "    # creates normalization obj in plt, based on min and max coefficient values\n",
    "    normalized = plt.Normalize(coef_df['coefficient'].min(), coef_df['coefficient'].max())\n",
    "    # defines color map\n",
    "    cmap = sns.color_palette('coolwarm', as_cmap=True)\n",
    "    # applies color map based on normalized coefficients to get positive/negative effect visualized\n",
    "    colors = cmap(normalized(coef_df['coefficient']))\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x='coefficient', y='feature', data=coef_df, palette=colors)\n",
    "    plt.title('Logistic Regression Feature Importance')\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def run_pipeline(df, num_cols, cat_cols, target='target'):\n",
    "    \"\"\"Runs above pipeline & evaluation steps on given data, returns the model.\"\"\"\n",
    "\n",
    "    # define column types\n",
    "    \n",
    "\n",
    "    # define feature and target space\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target] \n",
    "\n",
    "    # creates preprocessor & model pipeline\n",
    "    preprocessor = build_preprocessor(num_cols, cat_cols)\n",
    "    model_pipeline = build_model(preprocessor)\n",
    "    \n",
    "    \n",
    "    # cv scores\n",
    "    evaluate_model_cv(model_pipeline, X, y, cv=5)\n",
    "\n",
    "    # train and evaluate model\n",
    "    model, X_test, y_test = train_model(model_pipeline, X, y)\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a392577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save=True):\n",
    "    \"\"\"Saves the final model.\"\"\"\n",
    "    if not save:\n",
    "        return\n",
    "    joblib.dump(model, 'heart_disease_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main driver function\n",
    "def main():\n",
    "\n",
    "    # load in dataset with duplicates removed\n",
    "    df = pd.read_csv('heart.csv')\n",
    "\n",
    "    \n",
    "    # inspect data\n",
    "    check_basic_info(df, show=True)\n",
    "\n",
    "    # EDA, first defining col types for it (note: some numerical cols function as categoricals)\n",
    "    eda_num_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    eda_cat_cols = ['cp',  'restecg', 'slope', 'thal', 'ca']\n",
    "    eda_bin_cols = ['sex', 'fbs', 'exang']\n",
    "    eda_utility(df, eda_cat_cols, eda_num_cols, eda_bin_cols, plot=False, save=False)\n",
    "\n",
    "    # Define col types for model\n",
    "    model_num_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    model_cat_cols = ['cp',  'restecg', 'slope', 'thal', 'ca', 'sex', 'fbs', 'exang']\n",
    "    \n",
    "    # Prepare data for model, run all model & evaluation steps\n",
    "    df = clean_for_pipeline(df)\n",
    "    model = run_pipeline(df, model_num_cols, model_cat_cols)\n",
    "    get_feature_importance(model, model_num_cols, model_cat_cols)\n",
    "\n",
    "    # Optionally save model\n",
    "    save_model(model, save=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d75798",
   "metadata": {},
   "source": [
    "## Model Performance & Generalizability\n",
    "5-fold cross validation shows that the data in question has a mean ROC-AUC of approximately 0.91 (± 0.04), indicating solid performance. It shows moderate variability, which is expected given the small dataset size. In order to create a model that stabilizes further and generalizes to wider data, it would be important to gather a larger dataset. Further improvements based on the current data may risk overfitting the model to noise within this dataset rather than capturing true general signal.\n",
    "\n",
    "\n",
    "## Feature Contributions\n",
    "The feature importance plot displays model coefficients, showing how each feature affects prediction. Red features on the right contribute to the chance of heart disease diagnosis, while blue features on the left contribute against. The intensity of the color and length of the bar indicate how important that feature is weighted in making predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (heart-venv)",
   "language": "python",
   "name": "heart-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
